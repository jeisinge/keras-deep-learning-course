Understand neural networks through simulations : http://playground.tensorflow.org

Data -> Loss(theta)
  theta - model parameters
  Deraitives for minizing loss

Fitting a line
 * Wx + b = y
 * theta = {w, b}
 * loss = for each point, sum distance from line squared

Activation - sigmoid -> for any number, (0,1)
  * non linear

Logistic Regression - fitting a line with vectors

ReLU - nothing until an activation

Mu input_dim
  * Softmax - turn results to probabilities for multiclass

Neural Network defined by data and network

input format - always numerical

Embedding(dimension, vocabulary)
 * input_dim - vocab size
 * output_dim - embedding size - number of output variables
 * input_length - number of words

Sequential
 * input_dim = MAX_FEATURES words in vocab, VOCAB_SIZE
 * output_dim = EMBEDDING_DIMS - 
 * input_length = number of words in review for max




